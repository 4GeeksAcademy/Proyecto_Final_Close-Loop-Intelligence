{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74db5332",
   "metadata": {},
   "source": [
    "# Paso 6: Construye el modelo y optimízalo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7a896a",
   "metadata": {},
   "source": [
    "### Elección del Modelo y Entrenamiento: Dada la naturaleza de clasificación, hemos decidido explorar los modelos de Regresión Logística, Random Forest y XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe69bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"/workspaces/Proyecto_Final_Close-Loop-Intelligence/data/processed/X_train_selected.csv\")\n",
    "test_data = pd.read_csv(\"/workspaces/Proyecto_Final_Close-Loop-Intelligence/data/processed/X_test_selected.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2066ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en características (X) y variable objetivo (y)\n",
    "\n",
    "X_train = train_data.drop(columns=['ClasificacionABC'])\n",
    "y_train = train_data['ClasificacionABC']\n",
    "X_test = test_data.drop(columns=['ClasificacionABC'])\n",
    "y_test = test_data['ClasificacionABC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ver qué hay realmente en la columna\n",
    "print(train_data['ClasificacionABC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfbf18",
   "metadata": {},
   "source": [
    "### 1) Modelo de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb096cac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      3\u001b[39m model = LogisticRegression()\n\u001b[32m      4\u001b[39m model.fit(X_train, y_train)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones y evaluación del modelo\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b655e",
   "metadata": {},
   "source": [
    "El modelo predice solo la clase 0, entendemos que se debe al desbalance de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb438ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones y evaluación del modelo\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b772ac",
   "metadata": {},
   "source": [
    "### 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state = 42,class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones y evaluación del modelo\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Optimización del modelo\n",
    "\n",
    "grid_search = GridSearchCV (rf_model, param_grid=hyperparameters, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ajustar el modelo con los datos\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 2. Obtener el mejor modelo\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42015025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predicciones y Evaluación\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Reporte de Clasificación (Random Forest Optimizado) ---\")\n",
    "report_rf_optimized = classification_report(y_test, y_pred_rf)\n",
    "accuracy_rf_optimized = accuracy_score(y_test, y_pred_rf)\n",
    "print(report_rf_optimized)\n",
    "\n",
    "print(\"\\n--- Matriz de Confusión ---\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51bf863",
   "metadata": {},
   "source": [
    "### 3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb962e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones y evaluación del modelo\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef535251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Optimización del modelo\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(xgb_model, hyperparameters, n_iter=10, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "# 1. Ajustar el modelo con los datos\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# 2. Obtener el mejor modelo\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "print(f\"Mejores parámetros: {random_search_xgb.best_params_}\")\n",
    "\n",
    "# 3. Predicciones y Evaluación\n",
    "y_pred_xgb_optimized = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"--- Reporte de Clasificación (XGBoost Optimizado) ---\")\n",
    "report_xgb_optimized = classification_report(y_test, y_pred_xgb_optimized)\n",
    "accuracy_xgb_optimized = accuracy_score(y_test, y_pred_xgb_optimized)\n",
    "print(report_xgb_optimized)\n",
    "\n",
    "print(\"\")\n",
    "print(\"--- Matriz de Confusión ---\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6753e7",
   "metadata": {},
   "source": [
    "**Conclusión General:**\n",
    "\n",
    "Ambos modelos lograron un accuracy similar. Sin embargo, considerando la naturaleza del problema de clasificación (con un desbalance de clases significativo), el **Random Forest optimizado** demuestra ser un modelo más equilibrado. Aunque su recall en las clases minoritarias no es extremadamente alto, es sustancialmente mejor que el de XGBoost, lo que lo hace más útil para identificar las instancias de las clases 1 y 2, que probablemente son de mayor interés para el negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10143585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado del modelo\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(best_rf, open('/workspaces/Proyecto_Final_Close-Loop-Intelligence/models/best_rf_model.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
